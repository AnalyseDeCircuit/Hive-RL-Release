# 修复 must_place_queen_violation 比例过高的问题

## 问题分析

根据训练日志，当前存在以下问题：
1. **must_place_queen_violation 比例过高**：约46.3%的游戏因此结束
2. **epsilon 衰减过快**：在第5000轮时已降到0.4，但AI仍大量违反基本规则
3. **学习效率低**：大量游戏因违规而提前结束，无法进行有效的策略学习

## 修复方案

### 1. 减慢 Epsilon 衰减速度

**文件**: `ai_trainer.py`

**修改内容**:
- Foundation阶段：epsilon从0.9->0.7，衰减周期从15000增加到25000轮
- Strategy阶段：epsilon从0.7->0.3，衰减周期从20000增加到30000轮  
- Mastery阶段：epsilon从0.3->0.05，衰减周期从15000增加到20000轮

**目的**: 给AI更多时间学习基本规则，特别是在foundation阶段保持更高的探索率

### 2. 大幅提升违规惩罚

**文件**: `hive_env.py`

**修改内容**:
- 必须放置蜂后违规惩罚：从-10.0提升到-20.0
- 原有奖励系统中同样提升惩罚到-20.0

**目的**: 让AI更强烈地意识到违反必须放置蜂后规则的严重性

### 3. 增强正确行为的奖励

**文件**: `hive_env.py`

**修改内容**:
- 必须放置蜂后时正确放置：奖励+2.0
- 正常情况下放置蜂后：奖励+1.0
- 非蜂后棋子放置：奖励+0.05

**目的**: 通过正向激励引导AI学习正确的行为模式

### 4. 更新奖励整形系统

**文件**: `improved_reward_shaping.py`

**修改内容**:
- Foundation阶段非法动作惩罚：从-0.8提升到-5.0
- Strategy阶段非法动作惩罚：从-0.6提升到-3.0
- Mastery阶段非法动作惩罚：从-1.0提升到-5.0

**目的**: 在所有阶段都保持对违规行为的强烈抑制

## 预期效果

1. **降低违规比例**：通过更严厉的惩罚和更强的正向激励，预期must_place_queen_violation比例从46%降低到10%以下
2. **提高学习效率**：更多的游戏能够正常进行，AI有更多机会学习策略
3. **更好的规则遵守**：AI在基础阶段就能牢固掌握基本规则

## 训练建议

1. **监控违规率**：密切关注must_place_queen_violation的比例变化
2. **观察奖励曲线**：正确放置蜂后应该能获得更稳定的正奖励
3. **阶段性评估**：在foundation阶段结束时（40000轮）评估违规率是否显著下降

## 长期优化方向

如果违规率仍然较高，可以考虑：
1. 进一步减慢epsilon衰减
2. 增加专门的"规则学习"预训练阶段
3. 使用课程化学习，先训练简化版本的游戏

---

**修改时间**: 2025年7月2日  
**修改文件**: ai_trainer.py, hive_env.py, improved_reward_shaping.py
